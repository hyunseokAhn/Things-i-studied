# -*- coding: utf-8 -*-
"""4. CNN-VGG 16

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1YEHVZNaep0RVdxzLzI68dMovHcnaa2Bu

##### paper에 있는 모든 사항을 전부 반영하지는 않았지만 약간의 수정과 더불어 대부분의 사양을 반영하였다.(안한 것들은 주석처리해둠) image classifier가 실제 project에서 사용되고 이때 VGG의 사용이 고려된다면 조금 더 투자하여 완벽한 model을 만드는 것으로 한다.

## Connect my Google drive, Import modules
"""

# Connect my Google drive
from google.colab import drive

drive.mount('/gdrive')
gdrive_root = '/gdrive/My Drive/Research/basic_program' # 폴더 위치 생각하고 연결하기

# Import modules
import os
import matplotlib.pyplot as plt
import numpy as np
import random
import PIL
from PIL import Image
import torch
import torch.optim as optim
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import DataLoader
import torchvision
from torchvision import transforms

torch.manual_seed(1) 
torch.cuda.manual_seed(1)

"""## Choose Hyper-parameters and  Initialize"""

# Choose Hyper-parameters(training & optimization)
max_epoch = 20
batch_size = 256 # 여기서 training scale(Multi-scale)은 사용하지 않았다.
learning_rate = 0.0005 # 0.01 -> 0.001 -> 0.0005까지 3번의 학습간 learning rate decay를 사용하였다.
output_dim = 10
p = 0.5
device = 'cuda'

"""## Construct data pipeline"""

# 여기에서 data agmentaion은 고려하지 않음
data_dir = os.path.join(gdrive_root, 'cifar10')
if not os.path.exists(data_dir):
  os.makedirs(data_dir)

# tensor로 변환과 각 chanel별 mean = 0.5, std = 0.5로 변환
transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])

train_dataset = torchvision.datasets.CIFAR10(root=data_dir, train=True, download=True, transform=transform)
train_dataloader = torch.utils.data.DataLoader(train_dataset,batch_size=batch_size, shuffle=True, num_workers=2)

test_dataset = torchvision.datasets.CIFAR10(root=data_dir, train=False, download=True, transform=transform)
test_dataloader = torch.utils.data.DataLoader(test_dataset,batch_size=batch_size, shuffle=False, num_workers=2)

"""## Check data set"""

classes = ('plane', 'car', 'bird', 'cat',
           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')

def imshow(img):
    npimg = img.numpy()
    plt.imshow(np.transpose(npimg, (1, 2, 0))) 


# get some random training images
dataiter = iter(train_dataloader) 
images, labels = dataiter.next() 

# show images
imshow(torchvision.utils.make_grid(images, normalize=True))

print(' '.join('%s' % classes[labels[j]] for j in range(4)))
# print dataset.shape
print(images.shape, labels.shape)

"""## Construct a neural network builder



"""

class MyClassifier(nn.Module):
  def __init__(self):
    super(MyClassifier, self).__init__()
    # 적용순서: Conv -> BN -> Activation function -> Dropout -> Pooling
    # paper에 있는 가중치 초기화 대신 같은 model의 이전에 학습한 best pre-trained model의 가중치를 사용하였다. 
    self.net = nn.Sequential(   
        nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding = 1), 
        nn.BatchNorm2d(32), 
        nn.ReLU(),
        nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, padding = 1), 
        nn.BatchNorm2d(32), 
        nn.ReLU(),
        nn.MaxPool2d(kernel_size=2, stride=2),

        nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding = 1),  
        nn.BatchNorm2d(64),
        nn.ReLU(), 
        nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding = 1),
        nn.BatchNorm2d(64),
        nn.ReLU(),

        nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding = 1),
        nn.BatchNorm2d(128),
        nn.ReLU(),
        nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding = 1),
        nn.BatchNorm2d(128),
        nn.ReLU(),
        nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding = 1),
        nn.BatchNorm2d(128),
        nn.ReLU(),
        nn.MaxPool2d(kernel_size=2, stride=2),

        nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding = 1),
        nn.BatchNorm2d(256),
        nn.ReLU(),
        nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding = 1),
        nn.BatchNorm2d(256),
        nn.ReLU(),
        nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding = 1),
        nn.BatchNorm2d(256),
        nn.ReLU(),
        nn.MaxPool2d(kernel_size=2, stride=2),

    )
    self.classifier = nn.Sequential(
        nn.Linear(in_features=256 * 4 * 4, out_features=2048), 
        nn.ReLU(),
        nn.Dropout(p),
        nn.Linear(in_features=2048, out_features=2048),
        nn.ReLU(),
        nn.Dropout(p),
        nn.Linear(in_features=2048, out_features=10)
    )

  def forward(self, x):
    x = self.net(x)
    x = x.view(-1, 256 * 4 * 4) 
    outputs = self.classifier(x)
    return outputs

"""## Initialize the network and optimizer"""

my_classifier = MyClassifier()
my_classifier = my_classifier.to(device)

print(my_classifier)

optimizer = optim.Adam(my_classifier.parameters(), lr=learning_rate)

"""## Load pre-trained weights if exist"""

ckpt_dir = os.path.join(gdrive_root, 'checkpoints')
if not os.path.exists(ckpt_dir):
  os.makedirs(ckpt_dir)

best_acc = 0.
ckpt_path = os.path.join(ckpt_dir, 'lastest.pt')
if os.path.exists(ckpt_path):
  ckpt = torch.load(ckpt_path)
  try:
    my_classifier.load_state_dict(ckpt['my_classifier'])
    optimizer.load_state_dict(ckpt['optimizer'])
    best_acc = ckpt['best_acc']
  except RuntimeError as e:
    print('wrong checkpoint')
  else:
    print('checkpoint is loaded !')
    print('current best accuracy : %.2f' % best_acc)

"""## Train the network"""

it = 0
train_losses = []
test_losses = []
for epoch in range(max_epoch):
  # train phase
  my_classifier.train()
  for inputs, labels in train_dataloader:
    print(inputs.shape)
    print(labels.shape)
    it += 1
    inputs = inputs.to(device)
    labels = labels.to(device)   
    logits = my_classifier(inputs)
    loss = F.cross_entropy(logits, labels)
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()
    acc = (logits.argmax(dim=1) == labels).float().mean() 

  # save losses in a list so that we can visualize them later.
  train_losses.append(loss)  

  # test phase / 여기서 Fully-Convolution layer로 변환하여 testing하는 것은 반영하지 않았다.
  n = 0.
  test_loss = 0.
  test_acc = 0.
  my_classifier.eval()
  for test_inputs, test_labels in test_dataloader:
    test_inputs = test_inputs.to(device)
    test_labels = test_labels.to(device)

    logits = my_classifier(test_inputs)
    test_loss += F.cross_entropy(logits, test_labels, reduction='sum').item() 
    test_acc += (logits.argmax(dim=1) == test_labels).float().sum().item() 
    n += test_inputs.size(0)

  test_loss /= n
  test_acc /= n
  test_losses.append(test_loss)

  print('[epoch:{}, iteration:{}] train loss : {:.4f} train accuracy : {:.4f}'.format(epoch, it, loss.item(), acc.item())) 
  print('[epoch:{}, iteration:{}] test_loss : {:.4f} test accuracy : {:.4f}'.format(epoch, it, test_loss, test_acc)) 


  # save checkpoint whenever there is improvement in performance
  if test_acc > best_acc:
    best_acc = test_acc
    ckpt = {'my_classifier':my_classifier.state_dict(),
              'optimizer':optimizer.state_dict(),
              'best_acc':best_acc}
    torch.save(ckpt, ckpt_path)
    print('checkpoint is saved !')

"""## Visualize the training process"""

# 이미 학습을 상당량 거치고 시각화를 하여서 그 전까지의 data가 기록되지 않았다. 다음번에는 첫 학습부터 data를 기록하여 시각화해보자
plt.plot(train_losses, label='train loss')
plt.plot(test_losses, label='test loss')
plt.xlabel('epoch')
plt.ylabel('loss')
plt.xlim([0, 20])
plt.ylim([0, 1.5])
plt.legend()

my_classifier.load_state_dict(ckpt['my_classifier'])
optimizer.load_state_dict(ckpt['optimizer'])

"""## Result"""

# Testing(best model로 단 한번한 test하는 것) 
n = 0.
test_loss = 0.
test_acc = 0.
my_classifier.eval()
for test_inputs, test_labels in test_dataloader:
  test_inputs = test_inputs.to(device)
  test_labels = test_labels.to(device)

  logits = my_classifier(test_inputs)
  test_loss += F.cross_entropy(logits, test_labels, reduction='sum').item()
  test_acc += (logits.argmax(dim=1) == test_labels).float().sum().item()
  n += test_inputs.size(0) 

test_loss /= n
test_acc /= n

print('Test_loss : {:.4f}, Test accuracy : {:.4f}'.format(test_loss, test_acc))

"""## Analyze the results"""

my_classifier.eval()

num_test_samples = len(test_dataset)
random_idx = random.randint(0, num_test_samples)
classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')

test_input, test_label = test_dataset.__getitem__(random_idx) 
test_prediction = F.softmax(my_classifier(test_input.unsqueeze(0).to(device)), dim=1).argmax().item()
print('label : %s' % classes[test_label])
print('prediction : %s' % classes[test_prediction])

# functions to show an image
def imshow(img):
    img = img / 2 + 0.5  
    npimg = img.numpy()
    plt.imshow(np.transpose(npimg, (1, 2, 0)))

# show images
imshow(torchvision.utils.make_grid(test_input))

