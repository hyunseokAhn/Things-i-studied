# -*- coding: utf-8 -*-
"""6. CNN-ResNet

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1H_bksawDBXhmsjgvrjtTHzqFLNxTcnaL

우선 paper에 cifar10용 resnet을 살펴보면 sota의 성능을 내진 못하고 참고용으로만 설계하였다고 되어있다.(쉽게 생각하면 가벼운 task에서는 다른 network가 더 유용하다고 생각하면 편할 것 같다.)

네트워크 구조는 여러개가 있지만 구현해볼 적당한 32-layer를 살펴보면 우선 첫번째 layer는 3x3filter를 32x32x16 size의 feature map이 나오도록 사용하고 depth가 16 / 32 / 64가 되도록 block을 5개씩 넣으면 된다.(각 depth part별로 10-layer) 마지막으로 output의 개수가 10개가 되도록 fc layer를 넣으면 된다.

학습의 방법은 다음과 같다.
1. weight decay of 0.0001 and momentum of 0.9
2. weight initialization
3. BN
4. batchsize=128
5. 0.1 learning rate --> 멈출때마다 1/10 with SGD
6. simple data augmentation / 4 pixel side padding + 32 random crop + horizontal flip

여기서 5번 항목을 성능 향상을 위하여 adam으로 변경한다. 또한 data augmentation 연습이 목적이 아니므로 6번은 flip만 사용하도록한다.

## Connect my Google drive, Import modules
"""

# Connect my Google drive
from google.colab import drive

drive.mount('/gdrive')
gdrive_root = '/gdrive/My Drive/Study/Machine Learning/basic program/6. CNN-ResNet' # 폴더 위치 생각하고 연결하기

# Import modules
import os
import matplotlib.pyplot as plt
import numpy as np
import PIL
from PIL import Image
import easydict

import torch
import torch.optim as optim
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import DataLoader
import torchvision
from torchvision import transforms

torch.manual_seed(1) 
torch.cuda.manual_seed(1)
device = 'cuda'

"""## Create argment parser"""

# Choose Hyper-parameters
args = easydict.EasyDict({'max_epoch' : 50,
                          'batch_size' : 128,
                          'learning_rate' : 0.001,
                          'output_dim' : 10,
                          })

"""## Construct data pipeline"""

data_dir = os.path.join(gdrive_root, 'cifar10')
if not os.path.exists(data_dir):
  os.makedirs(data_dir)

# tensor로 변환과 각 chanel별 mean = 0.5, std = 0.5로 변환 + random horizontal flip
train_transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)), transforms.RandomHorizontalFlip(p=0.5)])
test_transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])

train_dataset = torchvision.datasets.CIFAR10(root=data_dir, train=True, download=True, transform=train_transform)
train_dataloader = torch.utils.data.DataLoader(train_dataset,batch_size=args.batch_size, shuffle=True, num_workers=2)

test_dataset = torchvision.datasets.CIFAR10(root=data_dir, train=False, download=True, transform=test_transform)
test_dataloader = torch.utils.data.DataLoader(test_dataset,batch_size=args.batch_size, shuffle=False, num_workers=2)

"""## Check data set"""

# batch_size=1로 setting 해야 사진 출력가능
classes = ('plane', 'car', 'bird', 'cat',
           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')

for inputs, label in train_dataloader:
  
    inputs = inputs.squeeze()
    inputs = inputs.numpy()
    inputs = inputs.transpose(1, 2, 0)
    plt.imshow(inputs)
    print(f'This image is {classes[label]}')
    break

"""## Construct a neural network builder



"""

class ResNet(nn.Module):
  def __init__(self):
    super(ResNet, self).__init__()
    self.first_layer = nn.Sequential(nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1),
                                     nn.BatchNorm2d(16),
                                     nn.ReLU())
    self.first_block = nn.Sequential(nn.Conv2d(in_channels=16, out_channels=16, kernel_size=3, stride=1, padding=1),
                                     nn.BatchNorm2d(16),
                                     nn.ReLU(),
                                     nn.Conv2d(in_channels=16, out_channels=16, kernel_size=3, stride=1, padding=1),
                                     nn.BatchNorm2d(16),)
    self.second_block = nn.Sequential(nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=1, padding=1),
                                     nn.BatchNorm2d(32),
                                     nn.ReLU(),
                                     nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=1, padding=1),
                                     nn.BatchNorm2d(32),)
    
    self.third_block = nn.Sequential(nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1),
                                     nn.BatchNorm2d(64),
                                     nn.ReLU(),
                                     nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1),
                                     nn.BatchNorm2d(64),)
    
    self.classifier = nn.Linear(in_features = 64 * 8 * 8, out_features = args.output_dim)
    # layer두개를 더 추가하여(channel변경 + feature map 1/2) 조금 더 간단히 resnet을 구현
    self.channel_change1 = nn.Sequential(nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1),
                                        nn.MaxPool2d(kernel_size=2, stride=2))
    self.channel_change2 = nn.Sequential(nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1),
                                        nn.MaxPool2d(kernel_size=2, stride=2))
    

  def forward(self, x):
    x = self.first_layer(x)
    
    for i in range(5):
      x1 = x
      x = self.first_block(x)
      x = x1 + x
      x = F.relu(x)
    
    x = self.channel_change1(x)
    
    for i in range(5):
      x2 = x
      x = self.second_block(x)
      x = x2 + x
      x = F.relu(x)
    
    x = self.channel_change2(x)
    
    for i in range(5):
      x3 = x
      x = self.third_block(x)
      x = x3 + x
      x = F.relu(x) 
    
    x = x.view(-1, 64 * 8 * 8)
    
    x = self.classifier(x)
    return x

"""## Initialize the network, optimizer and loss function"""

my_classifier = ResNet()
my_classifier = my_classifier.to(device)
loss_function = nn.CrossEntropyLoss()
optimizer = optim.Adam(my_classifier.parameters(), lr=args.learning_rate, weight_decay=0.01)

"""## Load pre-trained weights if exist

"""

ckpt_dir = os.path.join(gdrive_root, 'checkpoints')
if not os.path.exists(ckpt_dir):
  os.makedirs(ckpt_dir)

best_acc = 0.
ckpt_path = os.path.join(ckpt_dir, 'lastest.pt')
if os.path.exists(ckpt_path):
  ckpt = torch.load(ckpt_path)
  try:
    my_classifier.load_state_dict(ckpt['my_classifier'])
    optimizer.load_state_dict(ckpt['optimizer'])
    best_acc = ckpt['best_acc']
  except RuntimeError as e:
    print('wrong checkpoint')
  else:
    print('checkpoint is loaded !')
    print('current best accuracy : %.2f' % best_acc)

"""## Train the network"""

train_losses = []
test_losses = []

# loss를 구하는 법에 차이가 있어서 완벽한 비교는 힘들지만 학습의 경향을 파악하는데 유의미한 차이는 없을 것으로 보이기에 학습은 이대로 진행한다.
for epoch in range(args.max_epoch):
  # train phase
  my_classifier.train()
  iter = 0
  loss_s = 0
  train_loss = 0
  for inputs, labels in train_dataloader:
    iter += 1
    inputs = inputs.to(device)
    labels = labels.to(device)   
    logits = my_classifier(inputs)
    loss = loss_function(logits, labels)
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()
    loss_s += loss
  train_loss = loss_s / iter
  train_losses.append(train_loss)

  # test phase 
  n = 0.
  test_loss = 0.
  test_acc = 0.
  my_classifier.eval()
  for test_inputs, test_labels in test_dataloader:
    test_inputs = test_inputs.to(device)
    test_labels = test_labels.to(device)
    logits = my_classifier(test_inputs)
    test_loss += F.cross_entropy(logits, test_labels, reduction='sum').item() 
    test_acc += (logits.argmax(dim=1) == test_labels).float().sum().item() 
    n += test_inputs.size(0)

  test_loss /= n
  test_acc /= n
  test_losses.append(test_loss)
  print(f'[epoch:{epoch+1}] train_loss : {train_loss:4f} test_loss : {test_loss:4f}')
  print(f'모델의 정확도는 {test_acc}입니다.')

  # save checkpoint whenever there is improvement in performance
  if test_acc > best_acc:
    best_acc = test_acc
    ckpt = {'my_classifier':my_classifier.state_dict(),
              'optimizer':optimizer.state_dict(), # optimizer도 학습을 하기에 저장이 필요하다.
              'best_acc':best_acc}
    torch.save(ckpt, ckpt_path)
    print('checkpoint is saved !')

"""## Visualize the training process"""

# 모델은 60%언저리의 정답률을 보이며 정답률이 높지 않은 가장 큰 이유는 overfitting으로 보인다. decay를 올리면서 학습을 진행 하였음에도 완전히 해결되지 않은 모습을 보인다.(약 60~70epoch 학습완료)
# data aumentation를 조금 더 해주고 decay와 learning rate를 적절히 조절해가며 model을 tunning 한다면 더 좋은 결과가 있겠지만 컴퓨팅 자원이 한정적이기에 여기까지만 학습을 진행한다.

plt.plot(train_losses, label='train loss')
plt.plot(test_losses, label='test loss')
plt.xlabel('epoch')
plt.ylabel('loss')
plt.xlim([0, 20])
plt.ylim([0, 4])
plt.legend()

my_classifier.load_state_dict(ckpt['my_classifier'])
optimizer.load_state_dict(ckpt['optimizer'])

print(len(train_losses))

